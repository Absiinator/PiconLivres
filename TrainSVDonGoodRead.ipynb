{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainSVDonGoodRead.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS5EKNpHfuFL"
      },
      "source": [
        "# Train SVD for recommandation system\n",
        "based on Goodread database's rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciQjoipS1nON"
      },
      "source": [
        "We're only using rating since it looks to be the most valuable information we have to determinate the best books a user may want to read.\\\n",
        "In implamentation, we will combine the results with some filtering of our own to give a user what we think is the list of most recommanded books."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4TG-f8Sf8f9"
      },
      "source": [
        "## data import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGWNmaJIfc1o",
        "outputId": "be96620a-482d-4137-809c-05acc121149a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "r = pd.read_csv('data/ratings.csv')\n",
        "r.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5976479 entries, 0 to 5976478\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Dtype\n",
            "---  ------   -----\n",
            " 0   user_id  int64\n",
            " 1   book_id  int64\n",
            " 2   rating   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 136.8 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIQbhvIegF-o"
      },
      "source": [
        "Size reduction is necessary later to visualize cross validation results and save ressources.\\\n",
        "Random state is fixed for better reusability.\\\n",
        "this can be used as r if you want to train the model faster too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jCQKDh_fteu",
        "outputId": "16fd611c-c200-4991-800f-2d60c112b49b"
      },
      "source": [
        "rsample = r.sample(frac=0.1, random_state=42)\n",
        "rsample.info()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 597648 entries, 3623535 to 4905054\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count   Dtype\n",
            "---  ------   --------------   -----\n",
            " 0   user_id  597648 non-null  int64\n",
            " 1   book_id  597648 non-null  int64\n",
            " 2   rating   597648 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 18.2 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHKoJz99gX73"
      },
      "source": [
        "## model intialisation\n",
        "import SVD using previously determined best hyperparameters.\\\n",
        "(look into projectviz.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riKs5w3pgvki"
      },
      "source": [
        "from surprise import SVD\n",
        "from surprise import NormalPredictor, Dataset, Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# A reader is necessary while using another dataset than provided by surprise.\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# The columns must correspond to 'user id', 'item id' and 'rating' (in that order).\n",
        "data = Dataset.load_from_df(r[['user_id', 'book_id', 'rating']], reader)\n",
        "\n",
        "algo = SVD(n_epochs=20, lr_all=0.01, reg_all=0.2, verbose=True) # Verbose is used to visualize epochs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkUs7CKGk2kQ"
      },
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.15)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH4mQpRphlFF"
      },
      "source": [
        "## model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYo9w5H-qIgO"
      },
      "source": [
        "score visalisation of model using cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWcJqFkXpXpM",
        "outputId": "199cd072-d580-445f-8fd2-92851294e6c8"
      },
      "source": [
        "datasample = Dataset.load_from_df(rsample[['user_id', 'book_id', 'rating']], reader) # Here we are using a sample \n",
        "algosample = SVD(n_epochs=20, lr_all=0.01, reg_all=0.2) # Not using verbose for better vizualisation\n",
        "\n",
        "cross_validate(algosample, datasample, cv=3, verbose=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
            "RMSE (testset)    0.8996  0.8990  0.8983  0.8990  0.0005  \n",
            "MAE (testset)     0.7134  0.7134  0.7111  0.7126  0.0011  \n",
            "Fit time          27.92   27.93   28.20   28.02   0.13    \n",
            "Test time         5.99    8.05    6.05    6.70    0.96    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (27.920334815979004, 27.927778959274292, 28.200330018997192),\n",
              " 'test_mae': array([0.71340877, 0.71340772, 0.71108769]),\n",
              " 'test_rmse': array([0.89960682, 0.8989656 , 0.89833581]),\n",
              " 'test_time': (5.9923179149627686, 8.05149245262146, 6.0539870262146)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWDTXcL6rFJW"
      },
      "source": [
        "actual model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LTTrV7lhGmo",
        "outputId": "a8492a4b-9071-40d0-d4e1-1af0f8add8c9"
      },
      "source": [
        "from surprise import accuracy\n",
        "\n",
        "model = algo.fit(trainset)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing epoch 0\n",
            "Processing epoch 1\n",
            "Processing epoch 2\n",
            "Processing epoch 3\n",
            "Processing epoch 4\n",
            "Processing epoch 5\n",
            "Processing epoch 6\n",
            "Processing epoch 7\n",
            "Processing epoch 8\n",
            "Processing epoch 9\n",
            "Processing epoch 10\n",
            "Processing epoch 11\n",
            "Processing epoch 12\n",
            "Processing epoch 13\n",
            "Processing epoch 14\n",
            "Processing epoch 15\n",
            "Processing epoch 16\n",
            "Processing epoch 17\n",
            "Processing epoch 18\n",
            "Processing epoch 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYTTjmWt1fFN"
      },
      "source": [
        "## Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mfrjl980XoU"
      },
      "source": [
        "from pickle5 import pickle\n",
        "\n",
        "# Save to file in the current working directory\n",
        "pkl_filename = \"SVDmodel.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "# Load from file\n",
        "with open(pkl_filename, 'rb') as file:\n",
        "    pickle_model = pickle.load(file)"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}